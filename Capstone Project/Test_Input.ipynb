{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing pulling data from MAL and formatting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import pickle\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import requests\n",
    "from scipy.sparse import load_npz\n",
    "import re\n",
    "import ast\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import pos_tag, ne_chunk\n",
    "from nltk.tree import Tree\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Models/prediction_model.pkl', 'rb') as file:\n",
    "    model = pickle.load(file)\n",
    "\n",
    "with open('Models/tfidf_vectorizer.pkl', 'rb') as file:\n",
    "    vectorizer = pickle.load(file)\n",
    "\n",
    "with open('Models/rank_encoder.pkl', 'rb') as file:\n",
    "    rank_encoder = pickle.load(file)\n",
    "\n",
    "with open('Models/popularity_encoder.pkl', 'rb') as file:\n",
    "    popularity_encoder = pickle.load(file)\n",
    "\n",
    "with open('Models/score_encoder.pkl', 'rb') as file:\n",
    "    score_encoder = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape individual web_ids from MAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_id = '54857'\n",
    "\n",
    "def scrape_all(anime_id):\n",
    "    # Construct the URL using the anime ID\n",
    "    url = f\"https://myanimelist.net/anime/{anime_id}\"\n",
    "    \n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to retrieve data. HTTP status code: {response.status_code}\")\n",
    "        return None\n",
    "    \n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # Extract the entire page content as plain text\n",
    "    page_text = soup.get_text(separator=\"\\n\", strip=True)\n",
    "    \n",
    "    return page_text\n",
    "\n",
    "\n",
    "anime_data = scrape_all(anime_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_list = anime_data.split('\\n')\n",
    "\n",
    "anime_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Column\n",
    "title = anime_list[0].split(' - ')[0]\n",
    "anime_list.pop(0)\n",
    "\n",
    "anime_dict['title'] = title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Type, Episodes, English Title, Source\n",
    "def parse_list(param, anime_list):\n",
    "    key = param.replace(':', '').strip().lower()\n",
    "    for i in range(len(anime_list)):\n",
    "        if anime_list[i].startswith(param):\n",
    "            anime_dict[key] = anime_list[i + 1].strip() \n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_list('Type:', anime_list)\n",
    "parse_list('Episodes:', anime_list)\n",
    "parse_list('English:', anime_list)\n",
    "parse_list('Source:', anime_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "synopsis_list = []\n",
    "\n",
    "found_index = -1\n",
    "\n",
    "for i in range(1, len(anime_list)):\n",
    "    if anime_list[i] == \"Synopsis\" and \"Edit\" in anime_list[i - 1]:\n",
    "        found_index = i\n",
    "        break\n",
    "\n",
    "if found_index != -1:\n",
    "    for i in range(found_index + 1, len(anime_list)):\n",
    "        if (anime_list[i].startswith(\"[Written by\") or \n",
    "            anime_list[i].startswith(\"Related Entries\") or \n",
    "            anime_list[i].startswith(\"Background\") or\n",
    "            anime_list[i].startswith(\"Edit\")):\n",
    "            break\n",
    "        \n",
    "        synopsis_list.append(anime_list[i])\n",
    "\n",
    "synopsis_list \n",
    "combined_synopsis = \" \".join((synopsis_list))\n",
    "anime_dict['synopsis'] = combined_synopsis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_types = ['Action', 'Adventure', 'Avant Garde', 'Award Winning', 'Boys Love', \n",
    "                  'Comedy', 'Drama', 'Ecchi', 'Erotica', 'Fantasy', 'Girls Love', \n",
    "                  'Gourmet', 'Hentai', 'Horror', 'Mystery', 'Romance', 'Sci-Fi', \n",
    "                  'Slice of Life', 'Sports', 'Supernatural', 'Suspense']\n",
    "\n",
    "found_genres = set()\n",
    "\n",
    "for entry in anime_list:\n",
    "    if entry in genres_types:\n",
    "        found_genres.add(entry)\n",
    "\n",
    "genres = \", \".join(found_genres)\n",
    "anime_dict['genres'] = genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_studios = [\n",
    "    \"Toei Animation\", \"Sunrise\", \"J.C.Staff\", \"Madhouse\", \n",
    "    \"TMS Entertainment\", \"Production I.G\", \"Studio Deen\", \n",
    "    \"Pierrot\", \"OLM\", \"Shin-Ei Animation\", \"A-1 Pictures\", \n",
    "    \"Nippon Animation\", \"AIC\", \"DLE\", \"Tatsunoko Production\", \"Trigger\"\n",
    "]\n",
    "\n",
    "found_studios = set()\n",
    "\n",
    "for entry in anime_list:\n",
    "    if entry in top_studios:\n",
    "        found_studios.add(entry)\n",
    "\n",
    "studios = \", \".join(found_studios)\n",
    "anime_dict['studios'] = studios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_producers = [\"Aniplex\", \"TV Tokyo\", \"Lantis\", \"Movic\", \n",
    "                 \"AT-X\", \"Bandai Visual\", \"Pony Canyon\", \"Kadokawa\", \n",
    "                 \"Dentsu\", \"Fuji TV\", \"NHK\", \"Sotsu\", \"KlockWorx\", \"Kodansha\", \"Shueisha\"]\n",
    "\n",
    "found_producers = set()\n",
    "for entry in anime_list:\n",
    "    if entry in top_producers:\n",
    "        found_producers.add(entry)\n",
    "\n",
    "producers = \", \".join(found_producers)\n",
    "anime_dict['producers'] = producers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "if anime_dict.get('episodes') == 'Unknown':\n",
    "    anime_dict['episodes'] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Re:Zero kara Hajimeru Isekai Seikatsu 3rd Season',\n",
       " 'type': 'TV',\n",
       " 'episodes': '16',\n",
       " 'english': 'Re:ZERO -Starting Life in Another World- Season 3',\n",
       " 'source': 'Light novel',\n",
       " 'synopsis': \"One year after the events at the Sanctuary, Subaru Natsuki trains hard to better face future challenges. The peaceful days come to an end when Emilia receives an invitation to a meeting in the Watergate City of Priestella from none other than Anastasia Hoshin, one of her rivals in the royal selection. Considering the meeting's significance and the potential dangers Emilia could face, Subaru and his friends accompany her. However, as Subaru reconnects with old associates and companions in Priestella, new formidable foes emerge. Driven by fanatical motivations and engaging in ruthless methods to achieve their ambitions, the new enemy targets Emilia and threaten the very existence of the city. Rallying his allies, Subaru must give his all once more to stop their and nefarious goals from becoming a concrete reality.\",\n",
       " 'genres': 'Fantasy, Drama, Suspense',\n",
       " 'studios': '',\n",
       " 'producers': 'AT-X, Kadokawa'}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anime_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now format the set so it can be used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>type</th>\n",
       "      <th>episodes</th>\n",
       "      <th>english</th>\n",
       "      <th>source</th>\n",
       "      <th>synopsis</th>\n",
       "      <th>genres</th>\n",
       "      <th>studios</th>\n",
       "      <th>producers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Re:Zero kara Hajimeru Isekai Seikatsu 3rd Season</td>\n",
       "      <td>TV</td>\n",
       "      <td>16</td>\n",
       "      <td>Re:ZERO -Starting Life in Another World- Season 3</td>\n",
       "      <td>Light novel</td>\n",
       "      <td>One year after the events at the Sanctuary, Su...</td>\n",
       "      <td>Fantasy, Drama, Suspense</td>\n",
       "      <td></td>\n",
       "      <td>AT-X, Kadokawa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              title  ...       producers\n",
       "0  Re:Zero kara Hajimeru Isekai Seikatsu 3rd Season  ...  AT-X, Kadokawa\n",
       "\n",
       "[1 rows x 9 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([anime_dict])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatize and vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "custom_words = {'and', 'the', 'is', 'a', 'to', 'it', 's', 'like', 'year'}\n",
    "pattern = r'\\b(?:' + '|'.join(re.escape(word) for word in custom_words) + r')\\b'\n",
    "\n",
    "def is_capitalized(word):\n",
    "    return word[0].isupper() and word.isalpha()\n",
    "\n",
    "# Too computationally expensive, not used\n",
    "def is_name(word, pos_tagged):\n",
    "    for chunk in ne_chunk(pos_tagged):\n",
    "        if isinstance(chunk, Tree):\n",
    "            for leaf in chunk.leaves():\n",
    "                if leaf[0] == word:\n",
    "                    return True\n",
    "    return False\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    if pd.isnull(text): \n",
    "        return text\n",
    "    words = word_tokenize(text)\n",
    "    pos_tagged = pos_tag(words)\n",
    "\n",
    "    lemmatized_words = [\n",
    "        lemmatizer.lemmatize(word.lower()) for word in words\n",
    "        if word.lower() not in stop_words and word.lower() not in custom_words and not is_capitalized(word)\n",
    "    ]\n",
    "    lemmatized_text = ' '.join(lemmatized_words)\n",
    "\n",
    "    ## Futher clean anything lemmatization missed, remove spaces and characters\n",
    "    cleaned_text = re.sub(r'[^\\w\\s]', '', lemmatized_text)\n",
    "    cleaned_text = re.sub(pattern, '', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()\n",
    "    \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['synopsis'] = X_test['synopsis'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "synopsis_tfidf = vectorizer.transform(X_test['synopsis'])\n",
    "tfidf_df = pd.DataFrame(synopsis_tfidf.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "tfidf_df.columns = ['tfidf_' + col for col in tfidf_df.columns]\n",
    "X_test = pd.concat([X_test, tfidf_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hot encode other columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "for producer in top_producers:\n",
    "    X_test[f'producer_{producer.replace(\" \", \"_\").lower()}'] = False\n",
    "\n",
    "for index, row in X_test.iterrows():\n",
    "    producers_in_row = row['producers']\n",
    "    \n",
    "    for producer in top_producers:\n",
    "        column_name = f'producer_{producer.replace(\" \", \"_\").lower()}'\n",
    "        if producer in producers_in_row:\n",
    "            X_test.at[index, column_name] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "for studio in top_studios:\n",
    "    X_test[f'studio_{studio.replace(\" \", \"_\").lower()}'] = False\n",
    "\n",
    "for index, row in X_test.iterrows():\n",
    "    studios_in_row = [studios.strip() for studios in row['studios'].split(',')]\n",
    "    \n",
    "    for studio in top_studios:\n",
    "        column_name = f'studio_{studio.replace(\" \", \"_\").lower()}'\n",
    "        if studio in studios_in_row:\n",
    "            X_test.at[index, column_name] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "for genre in genres_types:\n",
    "    X_test[f'Genres_{genre.replace(\" \", \"_\")}'] = False\n",
    "\n",
    "for index, row in X_test.iterrows():\n",
    "    genres_in_row = [genre.strip() for genre in row['genres'].split(',')]\n",
    "    \n",
    "    for genre in genres_types:\n",
    "        column_name = f'Genres_{studio}'\n",
    "        if genre in genres_in_row:\n",
    "            X_test.at[index, column_name] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['source'] = X_test['source'].replace('Unknown', np.nan)\n",
    "X_test['source'] = X_test['source'].replace('Mixed media', np.nan)\n",
    "X_test['source'] = X_test['source'].replace('Radio', np.nan)\n",
    "X_test['source'] = X_test['source'].replace('Card game', 'Game')\n",
    "X_test['source'] = X_test['source'].replace('Picture book', 'Book')\n",
    "X_test['source'] = X_test['source'].replace('Other', np.nan)\n",
    "X_test['source'] = X_test['source'].replace('Web manga', 'Manga')\n",
    "X_test['source'] = X_test['source'].replace('4-koma manga', 'Manga')\n",
    "X_test['source'] = X_test['source'].replace('Music', np.nan)\n",
    "X_test['source'] = X_test['source'].replace('Web novel', 'Book')\n",
    "X_test['source'] = X_test['source'].replace('Novel', 'Book')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_columns = ['Source_Book', 'Source_Game', 'Source_Light novel', 'Source_Manga', 'Source_Original', 'Source_Visual novel']\n",
    "type_columns = ['Types_Movie','Types_Music','Types_ONA','Types_OVA','Types_Special','Types_TV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in source_columns:\n",
    "    source_type = col.split('_')[-1]  \n",
    "    X_test[col] = X_test['source'].apply(lambda x: True if isinstance(x, str) and source_type in x else False)\n",
    "\n",
    "for col in type_columns:\n",
    "    type_value = col.split('_')[-1]  \n",
    "    X_test[col] = X_test['type'].apply(lambda x: True if isinstance(x, str) and type_value in x else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.drop(columns = ['synopsis', 'source', 'genres', 'studios', 'producers'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.MinMaxScaler()\n",
    "X_test[[\"episodes\"]] = scaler.fit_transform(df[[\"episodes\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('Data/training_set.csv')\n",
    "X_test = X_test.reindex(columns=df1.columns, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['anime_id', 'title', 'episodes', 'score', 'Popularity_category',\n",
       "       'Rank_category', 'Genres_Action', 'Genres_Adventure',\n",
       "       'Genres_Avant Garde', 'Genres_Award Winning',\n",
       "       ...\n",
       "       'producer_pony_canyon', 'producer_kadokawa', 'producer_dentsu',\n",
       "       'producer_fuji_tv', 'producer_nhk', 'producer_sotsu',\n",
       "       'producer_klockworx', 'producer_kodansha', 'producer_shueisha', 'year'],\n",
       "      dtype='object', length=239)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.drop(columns = ['title', 'anime_id', 'Popularity_category', 'Rank_category', 'score', 'popularity', 'rank', 'studios', 'year'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_score = y_pred[0].argmax(axis=1)\n",
    "y_pred_score = score_encoder.inverse_transform(y_pred_score)\n",
    "\n",
    "y_pred_pop = y_pred[1].argmax(axis=1)\n",
    "y_pred_pop = popularity_encoder.inverse_transform(y_pred_pop)\n",
    "\n",
    "y_pred_rank = y_pred[2].argmax(axis=1)\n",
    "y_pred_rank = rank_encoder.inverse_transform(y_pred_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['8'], dtype=object),\n",
       " array(['Top 500'], dtype=object),\n",
       " array(['Top 500'], dtype=object))"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_score, y_pred_pop, y_pred_rank"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
